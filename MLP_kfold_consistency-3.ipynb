{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scikitplot as skplt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-plot==0.3.7\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-plot==0.3.7) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.6/site-packages (from scikit-plot==0.3.7) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.6/site-packages (from scikit-plot==0.3.7) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.6/site-packages (from scikit-plot==0.3.7) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (1.17.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (2.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot==0.3.7) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot==0.3.7) (41.6.0.post20191030)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-plot==0.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.xlim(-0.5, len(np.unique(y))-0.5) # ADD THIS LINE\n",
    "    plt.ylim(len(np.unique(y))-0.5, -0.5) # ADD THIS LINE\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = pd.read_csv(\"results.csv\")\n",
    "original_input_features = input_features[['original_firstorder_10Percentile',\n",
    " 'original_firstorder_90Percentile',\n",
    " 'original_firstorder_Energy',\n",
    " 'original_firstorder_Entropy',\n",
    " 'original_firstorder_InterquartileRange',\n",
    " 'original_firstorder_Kurtosis',\n",
    " 'original_firstorder_Maximum',\n",
    " 'original_firstorder_MeanAbsoluteDeviation',\n",
    " 'original_firstorder_Mean',\n",
    " 'original_firstorder_Median',\n",
    " 'original_firstorder_Minimum',\n",
    " 'original_firstorder_Range',\n",
    " 'original_firstorder_RobustMeanAbsoluteDeviation',\n",
    " 'original_firstorder_RootMeanSquared',\n",
    " 'original_firstorder_Skewness',\n",
    " 'original_firstorder_TotalEnergy',\n",
    " 'original_firstorder_Uniformity',\n",
    " 'original_firstorder_Variance',\n",
    " 'original_glcm_Autocorrelation',\n",
    " 'original_glcm_JointAverage',\n",
    " 'original_glcm_ClusterProminence',\n",
    " 'original_glcm_ClusterShade',\n",
    " 'original_glcm_ClusterTendency',\n",
    " 'original_glcm_Contrast',\n",
    " 'original_glcm_Correlation',\n",
    " 'original_glcm_DifferenceAverage',\n",
    " 'original_glcm_DifferenceEntropy',\n",
    " 'original_glcm_DifferenceVariance',\n",
    " 'original_glcm_JointEnergy',\n",
    " 'original_glcm_JointEntropy',\n",
    " 'original_glcm_Imc1',\n",
    " 'original_glcm_Imc2',\n",
    " 'original_glcm_Idm',\n",
    " 'original_glcm_Idmn',\n",
    " 'original_glcm_Id',\n",
    " 'original_glcm_Idn',\n",
    " 'original_glcm_InverseVariance',\n",
    " 'original_glcm_MaximumProbability',\n",
    " 'original_glcm_SumEntropy',\n",
    " 'original_glcm_SumSquares',\n",
    " 'original_glrlm_GrayLevelNonUniformity',\n",
    " 'original_glrlm_GrayLevelNonUniformityNormalized',\n",
    " 'original_glrlm_GrayLevelVariance',\n",
    " 'original_glrlm_HighGrayLevelRunEmphasis',\n",
    " 'original_glrlm_LongRunEmphasis',\n",
    " 'original_glrlm_LongRunHighGrayLevelEmphasis',\n",
    " 'original_glrlm_LongRunLowGrayLevelEmphasis',\n",
    " 'original_glrlm_LowGrayLevelRunEmphasis',\n",
    " 'original_glrlm_RunEntropy',\n",
    " 'original_glrlm_RunLengthNonUniformity',\n",
    " 'original_glrlm_RunLengthNonUniformityNormalized',\n",
    " 'original_glrlm_RunPercentage',\n",
    " 'original_glrlm_RunVariance',\n",
    " 'original_glrlm_ShortRunEmphasis',\n",
    " 'original_glrlm_ShortRunHighGrayLevelEmphasis',\n",
    " 'original_glrlm_ShortRunLowGrayLevelEmphasis',\n",
    " 'original_glszm_GrayLevelNonUniformity',\n",
    " 'original_glszm_GrayLevelNonUniformityNormalized',\n",
    " 'original_glszm_GrayLevelVariance',\n",
    " 'original_glszm_HighGrayLevelZoneEmphasis',\n",
    " 'original_glszm_LargeAreaEmphasis',\n",
    " 'original_glszm_LargeAreaHighGrayLevelEmphasis',\n",
    " 'original_glszm_LargeAreaLowGrayLevelEmphasis',\n",
    " 'original_glszm_LowGrayLevelZoneEmphasis',\n",
    " 'original_glszm_SizeZoneNonUniformity',\n",
    " 'original_glszm_SizeZoneNonUniformityNormalized',\n",
    " 'original_glszm_SmallAreaEmphasis',\n",
    " 'original_glszm_SmallAreaHighGrayLevelEmphasis',\n",
    " 'original_glszm_SmallAreaLowGrayLevelEmphasis',\n",
    " 'original_glszm_ZoneEntropy',\n",
    " 'original_glszm_ZonePercentage',\n",
    " 'original_glszm_ZoneVariance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_firstorder_10Percentile</th>\n",
       "      <th>original_firstorder_90Percentile</th>\n",
       "      <th>original_firstorder_Energy</th>\n",
       "      <th>original_firstorder_Entropy</th>\n",
       "      <th>original_firstorder_InterquartileRange</th>\n",
       "      <th>original_firstorder_Kurtosis</th>\n",
       "      <th>original_firstorder_Maximum</th>\n",
       "      <th>original_firstorder_MeanAbsoluteDeviation</th>\n",
       "      <th>original_firstorder_Mean</th>\n",
       "      <th>original_firstorder_Median</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_SizeZoneNonUniformity</th>\n",
       "      <th>original_glszm_SizeZoneNonUniformityNormalized</th>\n",
       "      <th>original_glszm_SmallAreaEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666089</td>\n",
       "      <td>-0.231588</td>\n",
       "      <td>-0.062871</td>\n",
       "      <td>0.735072</td>\n",
       "      <td>0.432398</td>\n",
       "      <td>-0.426793</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.405379</td>\n",
       "      <td>-0.615686</td>\n",
       "      <td>-0.709659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099173</td>\n",
       "      <td>-0.400192</td>\n",
       "      <td>-0.327913</td>\n",
       "      <td>-1.585846</td>\n",
       "      <td>-1.664506</td>\n",
       "      <td>-0.606888</td>\n",
       "      <td>-0.684267</td>\n",
       "      <td>1.045467</td>\n",
       "      <td>-0.499621</td>\n",
       "      <td>-0.104014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.578095</td>\n",
       "      <td>-1.517206</td>\n",
       "      <td>-0.263500</td>\n",
       "      <td>-1.248924</td>\n",
       "      <td>-1.276448</td>\n",
       "      <td>-0.341963</td>\n",
       "      <td>-1.846960</td>\n",
       "      <td>-1.634193</td>\n",
       "      <td>-1.141716</td>\n",
       "      <td>-1.053343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110320</td>\n",
       "      <td>0.973585</td>\n",
       "      <td>-0.501190</td>\n",
       "      <td>-0.877703</td>\n",
       "      <td>-0.821587</td>\n",
       "      <td>-1.671904</td>\n",
       "      <td>1.261333</td>\n",
       "      <td>-1.613512</td>\n",
       "      <td>-0.034525</td>\n",
       "      <td>-0.104201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.622092</td>\n",
       "      <td>-0.524080</td>\n",
       "      <td>-0.283411</td>\n",
       "      <td>0.276127</td>\n",
       "      <td>-0.076564</td>\n",
       "      <td>-0.281625</td>\n",
       "      <td>-0.462375</td>\n",
       "      <td>-0.122580</td>\n",
       "      <td>-0.619277</td>\n",
       "      <td>-0.639993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116375</td>\n",
       "      <td>0.384715</td>\n",
       "      <td>-0.481904</td>\n",
       "      <td>0.878783</td>\n",
       "      <td>0.834547</td>\n",
       "      <td>-0.207904</td>\n",
       "      <td>0.150462</td>\n",
       "      <td>-1.122725</td>\n",
       "      <td>1.650846</td>\n",
       "      <td>-0.104464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.354726</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.564613</td>\n",
       "      <td>0.689698</td>\n",
       "      <td>0.348010</td>\n",
       "      <td>-0.454692</td>\n",
       "      <td>0.198209</td>\n",
       "      <td>0.306012</td>\n",
       "      <td>-0.356860</td>\n",
       "      <td>-0.505306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118485</td>\n",
       "      <td>-0.567314</td>\n",
       "      <td>0.735286</td>\n",
       "      <td>-0.734865</td>\n",
       "      <td>-0.655529</td>\n",
       "      <td>-0.333554</td>\n",
       "      <td>-0.656915</td>\n",
       "      <td>1.130329</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>-0.103984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.093786</td>\n",
       "      <td>0.640184</td>\n",
       "      <td>-0.195762</td>\n",
       "      <td>-0.388872</td>\n",
       "      <td>-0.263799</td>\n",
       "      <td>-0.048176</td>\n",
       "      <td>0.235202</td>\n",
       "      <td>-0.235861</td>\n",
       "      <td>1.021571</td>\n",
       "      <td>1.115583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106908</td>\n",
       "      <td>-0.656372</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>0.220707</td>\n",
       "      <td>0.288239</td>\n",
       "      <td>0.272257</td>\n",
       "      <td>-0.714476</td>\n",
       "      <td>0.306466</td>\n",
       "      <td>-0.835561</td>\n",
       "      <td>-0.092169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_firstorder_10Percentile  original_firstorder_90Percentile  \\\n",
       "0                         -0.666089                         -0.231588   \n",
       "1                         -0.578095                         -1.517206   \n",
       "2                         -0.622092                         -0.524080   \n",
       "3                         -0.354726                          0.007488   \n",
       "4                          1.093786                          0.640184   \n",
       "\n",
       "   original_firstorder_Energy  original_firstorder_Entropy  \\\n",
       "0                   -0.062871                     0.735072   \n",
       "1                   -0.263500                    -1.248924   \n",
       "2                   -0.283411                     0.276127   \n",
       "3                    0.564613                     0.689698   \n",
       "4                   -0.195762                    -0.388872   \n",
       "\n",
       "   original_firstorder_InterquartileRange  original_firstorder_Kurtosis  \\\n",
       "0                                0.432398                     -0.426793   \n",
       "1                               -1.276448                     -0.341963   \n",
       "2                               -0.076564                     -0.281625   \n",
       "3                                0.348010                     -0.454692   \n",
       "4                               -0.263799                     -0.048176   \n",
       "\n",
       "   original_firstorder_Maximum  original_firstorder_MeanAbsoluteDeviation  \\\n",
       "0                     0.092516                                   0.405379   \n",
       "1                    -1.846960                                  -1.634193   \n",
       "2                    -0.462375                                  -0.122580   \n",
       "3                     0.198209                                   0.306012   \n",
       "4                     0.235202                                  -0.235861   \n",
       "\n",
       "   original_firstorder_Mean  original_firstorder_Median  ...  \\\n",
       "0                 -0.615686                   -0.709659  ...   \n",
       "1                 -1.141716                   -1.053343  ...   \n",
       "2                 -0.619277                   -0.639993  ...   \n",
       "3                 -0.356860                   -0.505306  ...   \n",
       "4                  1.021571                    1.115583  ...   \n",
       "\n",
       "   original_glszm_LargeAreaLowGrayLevelEmphasis  \\\n",
       "0                                     -0.099173   \n",
       "1                                     -0.110320   \n",
       "2                                     -0.116375   \n",
       "3                                     -0.118485   \n",
       "4                                     -0.106908   \n",
       "\n",
       "   original_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                -0.400192   \n",
       "1                                 0.973585   \n",
       "2                                 0.384715   \n",
       "3                                -0.567314   \n",
       "4                                -0.656372   \n",
       "\n",
       "   original_glszm_SizeZoneNonUniformity  \\\n",
       "0                             -0.327913   \n",
       "1                             -0.501190   \n",
       "2                             -0.481904   \n",
       "3                              0.735286   \n",
       "4                              0.038311   \n",
       "\n",
       "   original_glszm_SizeZoneNonUniformityNormalized  \\\n",
       "0                                       -1.585846   \n",
       "1                                       -0.877703   \n",
       "2                                        0.878783   \n",
       "3                                       -0.734865   \n",
       "4                                        0.220707   \n",
       "\n",
       "   original_glszm_SmallAreaEmphasis  \\\n",
       "0                         -1.664506   \n",
       "1                         -0.821587   \n",
       "2                          0.834547   \n",
       "3                         -0.655529   \n",
       "4                          0.288239   \n",
       "\n",
       "   original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                      -0.606888   \n",
       "1                                      -1.671904   \n",
       "2                                      -0.207904   \n",
       "3                                      -0.333554   \n",
       "4                                       0.272257   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                     -0.684267                    1.045467   \n",
       "1                                      1.261333                   -1.613512   \n",
       "2                                      0.150462                   -1.122725   \n",
       "3                                     -0.656915                    1.130329   \n",
       "4                                     -0.714476                    0.306466   \n",
       "\n",
       "   original_glszm_ZonePercentage  original_glszm_ZoneVariance  \n",
       "0                      -0.499621                    -0.104014  \n",
       "1                      -0.034525                    -0.104201  \n",
       "2                       1.650846                    -0.104464  \n",
       "3                      -0.072854                    -0.103984  \n",
       "4                      -0.835561                    -0.092169  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df=(original_input_features-original_input_features.mean())/original_input_features.std()\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Solid                168\n",
       "Part-solid            25\n",
       "Pure ground glass     11\n",
       "Peri-cystic            7\n",
       "Semiconsolidation      7\n",
       "Name: Nodule Consistency, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = pd.read_csv(\"NLST_data_processed_latest (1).csv\")\n",
    "targets = targets[[\"Nodule Consistency\", \"Nodule Margins\"]]\n",
    "Consistency = targets[[\"Nodule Consistency\"]]\n",
    "Consistency[\"Nodule Consistency\"].value_counts().plot(kind='bar')\n",
    "Consistency[\"Nodule Consistency\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.loc[targets[\"Nodule Consistency\"] != \"Solid\", \"Nodule Consistency\"] = \"Not Solid\"\n",
    "targets.loc[targets[\"Nodule Margins\"] != \"Smooth\", \"Nodule Margins\"] = \"Not Smooth\"\n",
    "targets[\"Nodule Consistency\"] = targets[\"Nodule Consistency\"].map(lambda x: 1.0 if x == \"Solid\" else 0.0)\n",
    "targets[\"Nodule Margins\"] = targets[\"Nodule Margins\"].map(lambda x: 1.0 if x == \"Smooth\" else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalized_df\n",
    "target = targets['Nodule Consistency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Fold Cross-validate\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.values\n",
    "y = target.values\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66608853, -0.23158802, -0.0628713 , ...,  1.04546652,\n",
       "        -0.49962074, -0.10401418],\n",
       "       [-0.57809479, -1.51720613, -0.26350012, ..., -1.61351167,\n",
       "        -0.03452509, -0.10420092],\n",
       "       [-0.62209166, -0.5240804 , -0.28341051, ..., -1.12272484,\n",
       "         1.65084631, -0.10446353],\n",
       "       ...,\n",
       "       [ 0.58409935,  0.50586617, -0.28787783, ..., -0.5389437 ,\n",
       "         0.11603436, -0.10382006],\n",
       "       [-1.49458336, -0.44369686, -0.11399223, ...,  0.48593096,\n",
       "         0.38476627, -0.10419669],\n",
       "       [-0.42241358, -0.31404598,  0.27829946, ...,  1.41118879,\n",
       "        -0.44823789, -0.10386192]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(72, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "#             nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['Nodule Consistency'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 50/50, Validation Loss: 1.2546954154968262\n",
      "Fold accuracy: 0.7045454545454546\n",
      "Fold AUC: 0.6323529411764706\n",
      "Fold #2\n",
      "Epoch 50/50, Validation Loss: 0.6947136521339417\n",
      "Fold accuracy: 0.9318181818181818\n",
      "Fold AUC: 0.85\n",
      "Fold #3\n",
      "Epoch 50/50, Validation Loss: 1.2799485921859741\n",
      "Fold accuracy: 0.7727272727272727\n",
      "Fold AUC: 0.6058823529411765\n",
      "Fold #4\n",
      "Epoch 50/50, Validation Loss: 0.9337743520736694\n",
      "Fold accuracy: 0.8604651162790697\n",
      "Fold AUC: 0.7348484848484849\n",
      "Fold #5\n",
      "Epoch 50/50, Validation Loss: 0.11190930008888245\n",
      "Fold accuracy: 0.9534883720930233\n",
      "Fold AUC: 0.9348484848484848\n"
     ]
    }
   ],
   "source": [
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "x = torch.tensor(features.values, dtype=torch.float32)\n",
    "y = torch.tensor(targets['Nodule Consistency'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "for train, test in kf.split(x, target):\n",
    "    fold += 1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    \n",
    "    model = NeuralNetwork().to(device)\n",
    "    ##print(model)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    \n",
    "    x_train = x[train]\n",
    "    x_test = x[test]\n",
    "    \n",
    "    y_train = y[train]\n",
    "    y_test = y[test]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = x_train.to(device), x_test.to(device), y_train.to(device), y_test.to(device)\n",
    "    # Training loop\n",
    "    EPOCHS = 50\n",
    "    epoch = 0\n",
    "   \n",
    "\n",
    "    while epoch < EPOCHS:\n",
    "        epoch += 1\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "#         print(output)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate validation loss\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val = model(x_test)\n",
    "            val_loss = criterion(y_val, y_test)\n",
    "\n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        y_val = model(x_test)\n",
    "        ##softmax\n",
    "        output = F.softmax(y_val, dim=1)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        ##print(torch.max(output, 1))\n",
    "    oos_y.append(y_test.cpu().numpy())\n",
    "    oos_pred.append(pred.cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS}, Validation Loss: \" f\"{val_loss.item()}\"\n",
    "    )\n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    score = metrics.accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "    print(f\"Fold accuracy: {score}\")\n",
    "    auc = metrics.roc_auc_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "    print(f\"Fold AUC: {auc}\")\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "\n",
    "# print(oos_y)\n",
    "# print(oos_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.8440366972477065\n",
      "Final AUC: 0.7513095238095239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63        50\n",
      "           1       0.88      0.92      0.90       168\n",
      "\n",
      "    accuracy                           0.84       218\n",
      "   macro avg       0.79      0.75      0.77       218\n",
      "weighted avg       0.84      0.84      0.84       218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = metrics.accuracy_score(oos_y, oos_pred)\n",
    "print(f\"Final accuracy: {score}\")\n",
    "auc = metrics.roc_auc_score(oos_y, oos_pred)\n",
    "print(f\"Final AUC: {auc}\")\n",
    "classification_report = metrics.classification_report(oos_y, oos_pred)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 29  21]\n",
      " [ 13 155]]\n"
     ]
    }
   ],
   "source": [
    "#compute the confusion matrix.\n",
    "cm = metrics.confusion_matrix(oos_y, oos_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 29  21]\n",
      " [ 13 155]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = np.array(['Not Solid','Solid'])\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(oos_y, oos_pred, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to MLP_kfold_consistency.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"MLP_kfold_consistency.pth\")\n",
    "print(\"Saved PyTorch Model State to MLP_kfold_consistency.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[ 0.0839, -0.0493, -0.0188,  ..., -0.0616,  0.1090, -0.1030],\n",
       "                      [-0.0087, -0.0549,  0.0395,  ..., -0.1108,  0.0478,  0.0540],\n",
       "                      [-0.1232,  0.1080,  0.1186,  ...,  0.0375, -0.0380, -0.0429],\n",
       "                      ...,\n",
       "                      [ 0.0670, -0.0593,  0.0109,  ...,  0.0556,  0.0207, -0.0506],\n",
       "                      [ 0.0149,  0.0239,  0.0351,  ...,  0.0819,  0.0032,  0.0794],\n",
       "                      [ 0.0507, -0.0847, -0.0656,  ..., -0.0211,  0.1108, -0.0160]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([-2.7904e-02,  5.2750e-02, -6.1556e-02,  1.6203e-02,  1.0690e-01,\n",
       "                       3.7473e-02,  2.4774e-02, -7.1062e-02,  1.1564e-01, -7.3280e-02,\n",
       "                       3.7044e-02, -9.2400e-02,  9.2757e-03,  1.1903e-01, -9.4495e-02,\n",
       "                       4.2708e-02, -5.4950e-02,  1.1682e-01,  1.1848e-01, -8.2482e-02,\n",
       "                      -5.5416e-02, -9.2573e-02,  1.1638e-01, -2.8659e-02,  1.1432e-01,\n",
       "                      -4.3056e-02, -5.8338e-02,  1.3017e-02,  1.2985e-01, -7.8827e-02,\n",
       "                      -1.0542e-01,  1.2213e-02, -1.6869e-02,  6.4685e-02, -2.0091e-02,\n",
       "                      -6.1876e-02,  5.0868e-02,  7.0830e-03,  7.8397e-02,  9.2657e-02,\n",
       "                      -6.9025e-02, -2.4678e-02, -5.6487e-02,  9.8471e-02,  1.0504e-01,\n",
       "                      -4.4669e-02,  2.6859e-04, -5.6474e-02,  2.8437e-02, -6.0453e-02,\n",
       "                      -1.9102e-02,  8.5144e-03,  2.9796e-02,  6.0074e-03, -1.3672e-02,\n",
       "                       2.9443e-02,  4.0915e-02, -9.9248e-02, -9.2293e-02,  7.2476e-02,\n",
       "                       5.8140e-02, -8.4485e-03, -3.8437e-02, -2.1405e-02,  1.0202e-02,\n",
       "                       1.1048e-01,  4.3561e-02, -3.7560e-02, -1.3334e-01,  6.4053e-02,\n",
       "                       1.3017e-01, -1.9430e-03,  6.1154e-02,  6.3814e-02,  3.7894e-02,\n",
       "                       8.3004e-02, -9.0169e-03, -4.9966e-03, -3.2664e-02, -8.8041e-02,\n",
       "                       8.3732e-02, -3.3126e-02, -2.8021e-02, -7.9120e-02, -5.8684e-02,\n",
       "                       5.6487e-02,  7.4888e-02, -9.2868e-02, -7.7357e-02,  4.3492e-02,\n",
       "                      -1.1279e-02, -1.0436e-01,  8.0869e-02,  1.2000e-01, -4.3590e-02,\n",
       "                      -4.3114e-02, -8.3819e-02,  3.8959e-02,  8.8924e-03, -1.1850e-01,\n",
       "                      -6.2463e-02,  1.2688e-01, -7.7369e-02, -8.7084e-02, -5.3902e-02,\n",
       "                       7.3437e-03,  2.0650e-02,  5.5661e-02, -8.8479e-02,  1.0956e-01,\n",
       "                       4.7853e-02, -5.5787e-02, -2.7561e-02,  3.4824e-02,  9.6010e-02,\n",
       "                       9.9888e-02, -7.6378e-03,  1.1639e-01, -5.5132e-03,  8.0040e-02,\n",
       "                      -8.4291e-02, -6.7534e-02, -8.3852e-02, -7.6696e-02, -3.2815e-02,\n",
       "                       7.1376e-02,  2.8020e-02, -7.1275e-02,  1.2076e-01, -9.5022e-03,\n",
       "                      -5.9040e-02, -1.1064e-01, -3.7913e-02,  7.2160e-02,  8.9160e-02,\n",
       "                      -8.0293e-02,  6.6188e-02,  1.1043e-01, -8.7200e-02,  1.0300e-02,\n",
       "                       2.8411e-02,  1.9372e-02,  2.2970e-02,  1.2410e-01,  4.2425e-02,\n",
       "                       4.3290e-02, -2.3397e-02, -6.8690e-02,  7.5879e-02, -1.1390e-02,\n",
       "                       3.6893e-02, -3.8059e-02, -4.1437e-02,  9.9438e-03,  1.1775e-01,\n",
       "                      -9.1264e-02,  3.7713e-02,  3.9223e-02, -5.3813e-02,  9.1993e-02,\n",
       "                      -1.0073e-01, -5.3829e-02, -5.4148e-02,  4.5755e-02,  5.2082e-02,\n",
       "                       8.2707e-02, -7.1593e-02, -1.0403e-01,  1.3552e-02, -8.1239e-02,\n",
       "                       9.9532e-02,  3.9099e-02, -9.0526e-02,  5.3590e-02, -4.3489e-02,\n",
       "                      -1.7397e-02, -9.6169e-02,  3.7258e-02,  1.1675e-01, -1.5199e-02,\n",
       "                       3.0149e-02, -2.4155e-02, -4.6957e-02,  7.6299e-02, -4.2188e-03,\n",
       "                      -3.1051e-02,  1.1311e-02,  8.4372e-02, -3.5318e-02, -1.0834e-01,\n",
       "                       6.9284e-02,  2.9271e-02,  5.9969e-02, -6.0176e-02, -3.1372e-02,\n",
       "                       7.6932e-02, -5.9454e-02, -8.3850e-02, -7.0357e-02,  4.4690e-02,\n",
       "                      -4.0433e-02, -8.2552e-02,  6.3820e-02,  1.2962e-01,  4.0069e-02,\n",
       "                       9.2683e-02,  3.5405e-03,  1.1237e-01, -8.0220e-02, -4.8553e-02,\n",
       "                       6.7768e-02,  1.0170e-01,  4.6086e-02,  4.4341e-02,  5.8843e-02,\n",
       "                      -1.1852e-02, -1.2370e-01, -4.1216e-02,  5.1698e-02, -5.0832e-02,\n",
       "                       4.7274e-02, -9.5949e-02,  1.0020e-01,  1.1667e-01,  6.4629e-02,\n",
       "                      -1.0435e-01,  3.6014e-03,  4.8744e-02, -8.5244e-02,  6.3387e-02,\n",
       "                      -6.8254e-02, -1.9593e-02,  1.0199e-01, -4.2281e-02, -7.5510e-02,\n",
       "                       4.4578e-03,  5.3505e-02,  7.1273e-02,  3.7453e-02,  3.3384e-02,\n",
       "                       6.3769e-02, -5.7459e-02, -3.3763e-02,  7.4993e-02,  6.2312e-02,\n",
       "                       5.7715e-02, -9.4406e-02, -5.5212e-02,  1.3034e-02,  1.7684e-02,\n",
       "                       9.1093e-02, -6.0505e-02, -4.0850e-02,  1.5501e-03,  2.5789e-02,\n",
       "                       2.0390e-02,  8.9369e-02,  1.2103e-01, -1.0886e-02,  6.1325e-02,\n",
       "                      -5.0108e-02, -2.3871e-02, -1.4190e-02, -7.4260e-02,  4.7829e-02,\n",
       "                      -1.4138e-03,  3.4791e-02,  9.6033e-02, -7.2207e-02,  1.0729e-01,\n",
       "                       7.1703e-02, -4.7523e-02, -3.6235e-02, -4.6539e-02,  1.1081e-01,\n",
       "                      -9.2601e-02,  5.1686e-02, -2.8181e-02, -5.1434e-02,  9.5026e-02,\n",
       "                       7.7660e-02, -1.1988e-01,  1.2606e-02,  9.9505e-03,  9.5776e-02,\n",
       "                      -2.3669e-02, -3.4775e-02, -7.8893e-02, -4.2361e-02,  1.0602e-01,\n",
       "                       1.2854e-02, -5.4994e-02, -7.1010e-02,  7.9670e-02,  7.9761e-02,\n",
       "                       1.0437e-01, -9.6447e-02,  5.7528e-02,  6.7340e-02,  4.9841e-02,\n",
       "                      -1.9828e-02,  9.8023e-02,  3.3362e-02,  5.6965e-02, -3.0708e-02,\n",
       "                       3.2819e-02,  7.0736e-02,  1.0817e-01,  8.9805e-02, -1.0145e-01,\n",
       "                       7.3430e-02,  3.5269e-02,  5.5817e-02, -3.8705e-02,  1.0132e-01,\n",
       "                      -4.0540e-02,  7.8135e-02, -4.1382e-02,  9.4007e-02, -7.4398e-02,\n",
       "                      -6.0811e-02,  5.6638e-03,  4.0575e-02, -3.1119e-03, -4.1137e-02,\n",
       "                      -6.4731e-02, -4.8479e-02, -1.2974e-02,  3.3852e-02,  3.9033e-02,\n",
       "                       9.2489e-02, -7.1807e-03, -7.7471e-02, -1.2576e-01,  1.6579e-02,\n",
       "                      -4.5561e-02,  1.5486e-03, -4.7370e-02,  5.8820e-02,  5.5651e-05,\n",
       "                      -2.0501e-02, -6.7915e-02, -1.6138e-02,  2.5858e-02,  7.6572e-02,\n",
       "                      -4.8942e-02,  7.3428e-02, -8.8702e-02, -1.1281e-01,  3.4362e-02,\n",
       "                      -1.0771e-01,  2.7705e-02,  1.1240e-02, -3.0743e-02,  1.1378e-01,\n",
       "                       1.2864e-01,  1.3031e-01, -8.2933e-02, -2.3875e-03, -5.9281e-02,\n",
       "                      -1.0749e-01,  9.1955e-02,  3.2830e-03, -1.2721e-01, -2.7445e-02,\n",
       "                      -6.0503e-02,  1.0607e-01, -1.1147e-01, -5.8782e-02,  5.9195e-02,\n",
       "                      -6.1731e-02, -1.7046e-02,  8.8601e-02, -3.7989e-02, -4.6400e-02,\n",
       "                       6.5693e-02, -9.5871e-02, -1.2139e-02, -4.9911e-02, -5.0872e-02,\n",
       "                       1.1839e-01,  1.0155e-01,  8.6077e-02, -3.8269e-02, -1.8986e-02,\n",
       "                       1.2112e-01,  6.2779e-02,  9.8285e-04, -8.2493e-02,  3.3945e-03,\n",
       "                      -5.6928e-02,  8.4060e-02, -7.6151e-02,  9.8221e-02,  2.8062e-02,\n",
       "                      -8.0335e-02,  3.9121e-02, -7.3713e-02,  7.6744e-02, -6.4593e-02,\n",
       "                      -3.4964e-02,  9.8935e-02, -8.7071e-02,  1.0622e-01, -7.9059e-02,\n",
       "                       7.6923e-02,  1.0978e-01,  2.2785e-03,  1.0351e-01,  3.5152e-02,\n",
       "                       2.3479e-02,  4.6354e-02, -3.6151e-02, -4.3016e-03, -5.0987e-04,\n",
       "                       7.4769e-02,  3.1711e-02,  6.6137e-02, -5.9135e-02,  7.0167e-02,\n",
       "                       3.0181e-02,  6.8547e-02,  9.1347e-03, -2.1818e-02, -8.0612e-02,\n",
       "                       3.7287e-02, -3.3305e-02, -9.6095e-02, -1.3930e-01,  1.1303e-01,\n",
       "                       1.2742e-01,  7.2121e-02, -1.2662e-02,  8.6459e-02,  2.7419e-02,\n",
       "                       7.1702e-02, -6.0398e-02, -2.0718e-02, -3.9857e-02, -1.0581e-01,\n",
       "                      -5.8967e-02,  3.0870e-02, -2.8658e-02,  3.7892e-03,  6.3307e-02,\n",
       "                      -7.0079e-02,  5.4299e-02, -9.0561e-02, -8.1141e-02, -4.7621e-02,\n",
       "                       1.2075e-01,  6.9046e-02,  5.0335e-02, -2.9437e-02,  2.5468e-02,\n",
       "                       6.7534e-03,  5.1719e-02, -9.4920e-03, -4.0852e-02, -3.0870e-02,\n",
       "                       1.7670e-02, -9.4675e-02, -8.7072e-02, -1.1061e-01,  3.6321e-02,\n",
       "                       1.0481e-01, -1.8931e-02, -1.0225e-01, -8.8373e-02,  3.1991e-02,\n",
       "                       8.0912e-03,  1.1652e-01, -5.9485e-02,  3.1061e-02,  4.5041e-02,\n",
       "                      -6.7500e-02,  6.5566e-02,  1.0420e-01,  1.0627e-01,  7.8618e-03,\n",
       "                      -1.3913e-02,  2.1017e-02,  1.1590e-01, -4.7286e-02, -5.4151e-02,\n",
       "                      -1.1141e-02, -1.1970e-02, -2.8038e-02, -1.6755e-02,  1.0745e-01,\n",
       "                      -4.5694e-03, -1.0371e-01,  9.9971e-02, -1.9776e-02, -3.9426e-02,\n",
       "                       9.8297e-02,  6.7991e-02, -9.4334e-02, -4.8319e-02,  1.1616e-01,\n",
       "                      -1.6519e-02, -1.0546e-01, -3.2514e-02,  2.0460e-02,  3.1690e-02,\n",
       "                       4.2669e-03,  1.3118e-01,  6.7141e-02,  4.0741e-02,  7.5200e-02,\n",
       "                       6.7831e-02, -7.0136e-02], device='cuda:0')),\n",
       "             ('linear_relu_stack.2.weight',\n",
       "              tensor([[ 0.0327,  0.0307,  0.0082,  ...,  0.0072,  0.0123,  0.0019],\n",
       "                      [ 0.0203, -0.0564,  0.0010,  ...,  0.0249, -0.0606, -0.0386],\n",
       "                      [ 0.0184, -0.0036, -0.0287,  ...,  0.0276, -0.0209,  0.0271],\n",
       "                      ...,\n",
       "                      [-0.0129,  0.0339, -0.0254,  ...,  0.0189,  0.0177, -0.0011],\n",
       "                      [-0.0109,  0.0344,  0.0165,  ...,  0.0007,  0.0374, -0.0233],\n",
       "                      [-0.0324,  0.0294,  0.0029,  ..., -0.0546, -0.0212, -0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.2.bias',\n",
       "              tensor([ 5.1213e-02,  1.4365e-02,  3.7926e-02, -1.8109e-02, -4.2210e-02,\n",
       "                      -2.7359e-02,  1.1469e-02,  2.8341e-02, -2.2896e-02, -4.4025e-02,\n",
       "                       1.1597e-02, -1.2290e-02,  4.1379e-02,  3.0116e-03, -4.7039e-02,\n",
       "                      -4.2970e-02, -3.6366e-04, -1.9297e-02, -5.1238e-03, -1.0892e-02,\n",
       "                      -7.6656e-03, -1.5519e-03, -2.4782e-02, -9.1738e-03,  4.3807e-02,\n",
       "                       2.9956e-02,  2.5534e-02,  2.2969e-02,  2.8331e-02,  1.5703e-02,\n",
       "                       5.4304e-02,  8.8781e-04, -3.8338e-02,  3.4427e-02,  1.8982e-02,\n",
       "                       4.2796e-02, -6.3090e-03, -2.2908e-02, -2.0720e-02, -1.2626e-03,\n",
       "                      -3.4256e-02, -3.7508e-02,  1.3988e-02,  5.9557e-03,  8.4510e-03,\n",
       "                       4.4692e-02,  1.2063e-02, -4.9830e-02, -2.2537e-03,  1.8438e-02,\n",
       "                       3.5164e-02, -4.7987e-03,  5.6909e-02, -3.5726e-02,  5.2286e-02,\n",
       "                      -5.0787e-02, -2.0401e-02,  5.5735e-02,  4.0792e-02,  8.4175e-03,\n",
       "                       2.8606e-02, -1.8242e-02,  3.0753e-02, -4.6084e-02, -1.4034e-03,\n",
       "                      -5.0563e-02, -2.1123e-03,  2.6358e-02,  8.3742e-03, -4.8006e-02,\n",
       "                      -1.6476e-02,  4.6387e-03,  3.5126e-02,  7.8155e-03, -3.3499e-02,\n",
       "                      -2.6057e-02,  4.9277e-03, -1.7169e-03, -3.5230e-02,  2.0299e-02,\n",
       "                      -1.5936e-03, -5.0593e-03,  1.9197e-02,  2.6022e-02, -2.7004e-02,\n",
       "                       2.9856e-02,  5.1364e-02, -3.5591e-02,  1.6574e-02, -1.1802e-02,\n",
       "                       2.3036e-03,  4.6728e-02,  4.3763e-02,  1.7273e-02,  9.3145e-03,\n",
       "                       2.1418e-02, -1.1204e-02,  5.8099e-02,  3.0165e-02,  4.3752e-02,\n",
       "                      -4.5538e-03, -5.9226e-03, -1.3128e-02, -3.5422e-02,  1.9823e-02,\n",
       "                      -2.7826e-03,  4.4412e-02, -2.2129e-02, -1.8476e-02, -2.7962e-02,\n",
       "                       2.7193e-02,  1.3255e-02,  5.6373e-03,  3.1835e-02, -1.1469e-02,\n",
       "                      -2.5617e-04, -1.5539e-03,  2.3231e-02, -1.2101e-02,  3.0769e-02,\n",
       "                      -2.0251e-02, -4.5376e-03,  3.9924e-02,  2.4339e-02,  2.1118e-02,\n",
       "                      -1.1044e-02, -2.7759e-02,  3.1579e-02,  4.8714e-02,  2.1051e-03,\n",
       "                      -7.2572e-03,  5.3543e-02,  2.8184e-02,  4.6963e-02,  1.3254e-03,\n",
       "                      -4.9986e-03,  2.5377e-02,  3.2014e-02,  3.9321e-02, -2.3289e-02,\n",
       "                       2.0629e-02, -3.3135e-02, -4.6789e-02, -3.5362e-02, -3.2424e-02,\n",
       "                       3.4668e-02, -3.7212e-02,  1.7856e-02, -2.5943e-02, -3.7389e-02,\n",
       "                       5.6023e-02, -7.9959e-03,  1.4548e-03, -1.2711e-02,  1.0370e-02,\n",
       "                      -2.7073e-02, -1.4022e-02, -2.5943e-02, -9.6044e-04, -2.1533e-02,\n",
       "                       5.4836e-02,  1.8586e-02,  2.9027e-02, -4.4225e-02, -1.4530e-02,\n",
       "                       1.1802e-02, -4.1307e-02, -3.2644e-03,  2.3880e-02, -1.2671e-02,\n",
       "                      -4.3059e-02,  2.2882e-02, -2.4865e-02,  2.5309e-02, -3.3746e-03,\n",
       "                       2.2062e-02, -2.1568e-02, -2.2881e-02,  3.4778e-03,  1.0661e-03,\n",
       "                      -1.9060e-02, -2.3291e-02,  1.5494e-02,  4.8624e-03,  1.1075e-02,\n",
       "                      -3.0692e-02,  3.3659e-03, -1.2260e-03, -9.5441e-03,  8.4430e-03,\n",
       "                      -1.9867e-02,  5.0134e-02,  4.7322e-02, -3.9159e-02,  1.8535e-02,\n",
       "                      -2.7437e-02,  2.9166e-02,  8.1837e-03,  8.3584e-03, -9.9095e-03,\n",
       "                       1.4198e-03, -9.0799e-03,  6.1377e-02,  1.2246e-02, -3.7697e-02,\n",
       "                      -4.7680e-03, -1.6571e-02, -6.4777e-05,  5.0380e-02, -5.0220e-02,\n",
       "                      -1.6461e-02, -4.0212e-02, -9.8164e-04, -1.3526e-02, -1.9544e-03,\n",
       "                       1.9394e-02, -4.6702e-02,  3.4946e-02,  3.5255e-02,  9.6060e-03,\n",
       "                      -4.4807e-02, -5.6115e-03, -4.5827e-02,  1.7716e-03,  1.9858e-04,\n",
       "                       2.5165e-02, -3.0567e-03, -3.1176e-02, -2.0419e-02,  4.0787e-02,\n",
       "                      -1.8912e-02, -4.1746e-02,  1.7964e-02, -2.5328e-02, -5.4115e-03,\n",
       "                       1.0437e-02,  2.7621e-02, -2.0270e-02, -2.1830e-02,  3.8710e-02,\n",
       "                      -3.2208e-03,  1.9200e-02, -2.4654e-03,  2.1163e-03,  1.0884e-02,\n",
       "                       5.1916e-02,  2.9250e-02,  6.4179e-04, -4.3450e-02,  3.0082e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.4.weight',\n",
       "              tensor([[ 0.0712, -0.0897, -0.0335,  ...,  0.0033,  0.0503, -0.0233],\n",
       "                      [-0.0643,  0.0784, -0.0070,  ..., -0.0374,  0.0209, -0.0237],\n",
       "                      [ 0.0527,  0.0105,  0.0156,  ..., -0.0199, -0.0287, -0.0186],\n",
       "                      ...,\n",
       "                      [-0.0410, -0.1002,  0.0316,  ...,  0.0689,  0.0428,  0.0682],\n",
       "                      [ 0.0375,  0.0081,  0.0460,  ..., -0.0073, -0.0400,  0.0648],\n",
       "                      [ 0.0030,  0.0158,  0.0374,  ...,  0.0066,  0.0628, -0.0417]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.4.bias',\n",
       "              tensor([-0.0261,  0.0262,  0.0286, -0.0099, -0.0444, -0.0558, -0.0285,  0.0585,\n",
       "                      -0.0322, -0.0501, -0.0486,  0.0535, -0.0293,  0.0124, -0.0318, -0.0428,\n",
       "                      -0.0016, -0.0147, -0.0376,  0.0528,  0.0243, -0.0472, -0.0279,  0.0275,\n",
       "                      -0.0569,  0.0659, -0.0278,  0.0192,  0.0121,  0.0186,  0.0585,  0.0051,\n",
       "                       0.0027, -0.0132,  0.0746, -0.0202, -0.0607,  0.0286, -0.0317,  0.0392,\n",
       "                      -0.0416, -0.0280,  0.0627,  0.0419,  0.0418, -0.0609,  0.0187, -0.0095,\n",
       "                      -0.0275,  0.0078,  0.0315,  0.0460, -0.0484, -0.0292,  0.0304,  0.0073,\n",
       "                       0.0280, -0.0237,  0.0292, -0.0521,  0.0408,  0.0276,  0.0193,  0.0467,\n",
       "                       0.0036, -0.0286, -0.0166,  0.0068,  0.0007,  0.0414, -0.0002,  0.0222,\n",
       "                      -0.0230,  0.0169, -0.0422, -0.0345,  0.0191,  0.0567, -0.0175, -0.0547,\n",
       "                      -0.0120,  0.0349, -0.0454,  0.0091,  0.0100, -0.0346,  0.0392,  0.0091,\n",
       "                      -0.0154,  0.0493,  0.0043,  0.0212, -0.0170,  0.0146, -0.0262, -0.0410,\n",
       "                       0.0415,  0.0196,  0.0307, -0.0488], device='cuda:0')),\n",
       "             ('linear_relu_stack.6.weight',\n",
       "              tensor([[-5.6931e-02,  1.1252e-01,  9.1099e-02,  4.3138e-02,  1.3137e-01,\n",
       "                        2.7995e-02, -3.1740e-02, -1.0172e-02,  4.7051e-02,  4.8530e-02,\n",
       "                       -9.3429e-02,  4.3910e-02, -2.2143e-03,  2.4227e-02,  2.8371e-02,\n",
       "                        6.1652e-02,  1.2458e-01, -9.7093e-02, -8.4285e-02,  8.5227e-02,\n",
       "                        3.4479e-02,  6.2129e-02,  7.7753e-02, -3.5844e-02, -9.5542e-02,\n",
       "                       -8.0185e-02, -6.1877e-02,  7.5600e-02,  2.0121e-02, -9.3936e-02,\n",
       "                        9.8843e-05,  9.7409e-02, -5.4916e-02,  3.6665e-02, -1.4641e-02,\n",
       "                       -5.5796e-02, -8.4030e-02, -1.1162e-02,  1.2574e-01, -1.0330e-01,\n",
       "                       -3.9482e-02,  1.1369e-01, -4.4299e-02,  9.3423e-02,  5.6415e-02,\n",
       "                       -1.0371e-01, -9.8914e-02,  5.6492e-02, -1.0569e-01,  2.9982e-03,\n",
       "                        4.1636e-02,  8.1699e-02,  1.0838e-01,  3.0646e-02, -4.2735e-02,\n",
       "                       -3.2914e-02,  7.6218e-02, -8.9671e-03,  2.1535e-02, -3.3796e-02,\n",
       "                        6.7446e-02,  7.1586e-02,  5.6455e-02, -7.7669e-02,  9.8155e-02,\n",
       "                        8.6187e-02,  5.1765e-03, -6.4686e-02, -5.2112e-03,  3.5533e-02,\n",
       "                        1.1472e-01,  6.5993e-02,  3.6277e-02,  5.2824e-02,  1.1552e-01,\n",
       "                        3.9042e-02, -1.0026e-01, -5.8777e-02, -9.4951e-02, -5.1368e-02,\n",
       "                       -1.9983e-03,  8.9810e-02,  1.0873e-01, -6.2557e-02, -1.1104e-01,\n",
       "                        5.6792e-02, -3.6989e-02, -9.8314e-03,  3.3956e-03,  4.8153e-02,\n",
       "                        1.1476e-02, -9.8155e-02,  2.9528e-02, -8.2025e-02, -8.7926e-02,\n",
       "                       -8.7203e-02,  8.7291e-02, -9.9464e-02, -9.8354e-02, -2.4099e-02],\n",
       "                      [ 5.8965e-02, -3.2557e-02, -3.8779e-02, -1.3047e-01,  1.5451e-02,\n",
       "                        4.1201e-02, -3.4394e-02,  1.1754e-01, -8.8397e-02, -1.7454e-02,\n",
       "                       -9.2748e-04, -1.0655e-01,  6.6870e-03,  1.1921e-01,  1.8496e-02,\n",
       "                        5.4498e-02, -1.3005e-01, -5.5086e-02,  1.1867e-01, -1.2504e-01,\n",
       "                        2.1589e-02,  9.8267e-03,  8.3474e-02, -2.7241e-02,  1.6896e-02,\n",
       "                        1.0505e-01,  1.3313e-02,  9.9160e-02,  6.6574e-02, -1.9744e-02,\n",
       "                        5.3182e-02,  7.0760e-02, -4.5438e-03, -2.5934e-02,  1.0936e-01,\n",
       "                       -8.2852e-02, -7.5228e-02, -4.6742e-02, -8.2506e-02,  2.0374e-02,\n",
       "                        1.0286e-01, -6.1869e-03,  9.5603e-02, -5.5411e-02, -1.3128e-02,\n",
       "                        7.0391e-02,  2.9440e-02, -5.0885e-02,  1.9340e-02,  1.0463e-01,\n",
       "                        1.1273e-01, -1.2598e-01,  5.2287e-02,  1.1791e-01,  5.0712e-02,\n",
       "                        1.0705e-02, -3.5890e-02,  9.9143e-02,  1.0961e-01,  8.2774e-02,\n",
       "                       -8.5825e-02,  8.8116e-03,  4.4953e-03,  6.6657e-02, -9.6534e-02,\n",
       "                        2.2721e-03,  1.0409e-01, -1.2025e-02,  3.4765e-02, -6.7432e-03,\n",
       "                        1.1513e-03,  6.2916e-02, -2.6175e-02, -1.0186e-01,  1.6699e-03,\n",
       "                        7.1913e-02,  4.8420e-02, -9.6961e-03,  1.1973e-02, -7.9626e-02,\n",
       "                        5.5695e-02,  5.2249e-02, -8.0823e-03, -9.0855e-02, -6.0926e-02,\n",
       "                       -8.3203e-02,  8.8120e-02,  8.2956e-02,  1.5190e-02, -4.9247e-02,\n",
       "                       -5.7116e-03,  1.0082e-01,  9.5946e-02,  8.8047e-02, -6.8882e-02,\n",
       "                        8.2738e-02, -6.2818e-02, -4.6097e-02, -3.6651e-02,  4.8446e-02]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear_relu_stack.6.bias',\n",
       "              tensor([-0.0425, -0.0589], device='cuda:0'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
